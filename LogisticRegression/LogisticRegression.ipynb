{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression By Farhan(2307)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing by encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
      "0      0              8            14              4             1        0\n",
      "1      1              6             9              4             1        0\n",
      "2      2              4            11              3             1        0\n",
      "3      3              3            10              5             1        0\n",
      "4      4              7            15              4             1        0\n",
      "..   ...            ...           ...            ...           ...      ...\n",
      "145  145             24             9             28            19        2\n",
      "146  146             20             4             26            15        2\n",
      "147  147             22             9             28            16        2\n",
      "148  148             19            13             30            19        2\n",
      "149  149             16             9             27            14        2\n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "le=LabelEncoder()\n",
    "for col in df.columns:\n",
    "  df[col]=le.fit_transform(df[col])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df.iloc[:,:-1].values\n",
    "y_data = df.iloc[:,-1].values\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohammed Farhan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression(random_state=1)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "Precision : 1.0\n",
      "Recall : 1.0\n",
      "accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "\n",
    "# recall and precision\n",
    "tp = cm[1][1]\n",
    "fp = cm[0][1]\n",
    "fn = cm[1][0]\n",
    "tn=cm[0][0]\n",
    "\n",
    "print(f'Precision : {tp/(tp+fp)}')\n",
    "print(f'Recall : {tp/(tp+fn)}')\n",
    "print(f'accuracy:{(tp+tn)/(tp+tn+fn+fp)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
